{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab62e347",
   "metadata": {},
   "source": [
    "L2CS-Net의 input은 \n",
    "1. 얼굴 부분 이미지 (나중에 모델의 dataset class가 448x448로 resize 하므로 크기 상관 없음)\n",
    "2. 3D Gaze 각도\n",
    "3. 2D Gaze 각도 \n",
    "\n",
    "각도 범위 180도 이내 조건 있은 확인 필요 (아마 2D에서만?) \n",
    "\n",
    "# To do\n",
    "pose 정보와 distance 정보들로 3D Gaze, 2D Gaze 계산\n",
    "\n",
    "그 외에는 일단 돌아갈 듯 함. L2CS-Net 모델링은 이걸로 끝? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74d21e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import random\n",
    "import nia22\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f175b000",
   "metadata": {},
   "source": [
    "Label  \n",
    "FORMAT:  \n",
    "Face left right origin 3DGaze 2DGaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a4f8f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_face(img, eye, factor = 1.5):\n",
    "    # factor = 1.5: 눈 사이 거리의 +/- 1.5배를 얼굴로 봄\n",
    "    both_eyes = np.array(eye.l_eyelid['points']+eye.r_eyelid['points'])\n",
    "\n",
    "    center = both_eyes.mean(axis=0).astype(int)\n",
    "\n",
    "    ll = np.array(eye.l_eyelid['points'])\n",
    "    rr = np.array(eye.r_eyelid['points'])\n",
    "\n",
    "    lc = np.mean(ll, axis=0)\n",
    "    rc = np.mean(rr, axis=0)\n",
    "\n",
    "    d_eyes = (np.sqrt(np.sum(np.square(lc - rc))) * factor).astype(int)\n",
    "\n",
    "    # make sure square and within the image boundary\n",
    "    lower = center - d_eyes\n",
    "\n",
    "    lower[lower < 0] = 0\n",
    "\n",
    "    upper = np.array([min((1920, lower[0] + 2*d_eyes)), min((1080, lower[1] + 2*d_eyes))])\n",
    "\n",
    "    aside = min((upper - lower))\n",
    "\n",
    "    upper[0] = lower[0] + aside\n",
    "    upper[1] = lower[1] + aside\n",
    "    \n",
    "    return img[lower[1]:upper[1], lower[0]:upper[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd044eb2",
   "metadata": {},
   "source": [
    "얼굴 crop  \n",
    "\n",
    "얼굴 = 양눈 중앙에서 위-아래로 양눈 거리 * n 만큼\n",
    "\n",
    "양 눈의 dx보다 dy가 더 큰 경우 = 이미지가 옆으로 누워있음. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06d925bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gaze2d(anno):\n",
    "    \"\"\"실제론 좀 더 복잡한 3D 변환이 필요함.\n",
    "    \"\"\"\n",
    "    return anno[\"Annotations\"][\"pose\"][\"head\"][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05ff54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/hoseung/Work/NIA/onecycle/l2cs/\"\n",
    "\n",
    "json_dir = \"/home/hoseung/Work/NIA/onecycle_final/json/\"\n",
    "png_dir = \"/home/hoseung/Work/NIA/onecycle_final/png/\"\n",
    "\n",
    "\n",
    "# output dir\n",
    "label_dir = \"./datasets/nia2022/Label/\"\n",
    "image_dir = \"./datasets/nia2022/Image/\"\n",
    "\n",
    "\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "os.makedirs(image_dir, exist_ok=True)\n",
    "os.makedirs(image_dir+\"test/\", exist_ok=True)\n",
    "os.makedirs(image_dir+\"train/\", exist_ok=True)\n",
    "os.makedirs(image_dir+\"val/\", exist_ok=True)\n",
    "\n",
    "cnt = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30234f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "jlist = glob(json_dir+\"*.json\")\n",
    "\n",
    "random.shuffle(jlist)\n",
    "\n",
    "# split the list of 원천데이터 8:1:1\n",
    "nj = len(jlist)\n",
    "ntest = nvalid = int(0.1*nj)\n",
    "\n",
    "jtest = jlist[:ntest]\n",
    "jvalid = jlist[ntest:ntest+nvalid]\n",
    "jtrain = jlist[ntest+nvalid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdd7995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304 304 2437\n"
     ]
    }
   ],
   "source": [
    "print(len(jtest), len(jvalid), len(jtrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7f1d9292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/nia2022/Image/'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14fbfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"test\"\n",
    "\n",
    "def make_dataset(fnlist, dtype, cnt=0):\n",
    "    dir_out = f\"{dtype}/\"\n",
    "    os.makedirs(image_dir+dir_out+\"Face\", exist_ok=True)\n",
    "    os.makedirs(image_dir+dir_out+\"Left\", exist_ok=True)\n",
    "    os.makedirs(image_dir+dir_out+\"Right\", exist_ok=True)\n",
    "\n",
    "    f = open(image_dir.replace(\"Image\", \"Label\") + f\"{dtype}.label\", \"w\")\n",
    "    f.write(\"Face Left Right Origin 3DGaze 2DGaze\")\n",
    "\n",
    "    # load png and anno\n",
    "    for fn_j in fnlist:\n",
    "        try:\n",
    "            anno = json.load(open(fn_j))\n",
    "            eye = nia22.eyes.Eye(anno[\"Annotations\"][\"image\"][\"annotations\"])\n",
    "\n",
    "            # read png\n",
    "            fn_png = fn_j.replace(\"json\", \"png\")\n",
    "            #img = cv2.cvtColor(cv2.imread(fn_png)) cv2.COLOR_BGR2RGB)\n",
    "            img = cv2.imread(fn_png)\n",
    "\n",
    "            cropped = cut_face(img, eye)\n",
    "\n",
    "            # compute 2D gaze from... ? \n",
    "            gaze2d = calculate_gaze2d(anno)\n",
    "            # save in Image and Label directory\n",
    "            fn_org = fn_png.split(\"/home/hoseung/Work/NIA/\")[1]\n",
    "            fn_face = dir_out + f\"Face/{cnt:06d}.jpg\"\n",
    "            fn_left = dir_out + f\"Left/{cnt:06d}.jpg\"\n",
    "            fn_right = dir_out + f\"Right/{cnt:06d}.jpg\" \n",
    "            f.write(f\"{fn_face} {fn_org} {gaze2d[0]},{gaze2d[1]}\\n\")\n",
    "\n",
    "            cv2.imwrite(image_dir + fn_face, cropped)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        cnt +=1\n",
    "\n",
    "    f.close()\n",
    "    return cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7672a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt 3045\n"
     ]
    }
   ],
   "source": [
    "cnt = make_dataset(jtrain, \"train\", 0)\n",
    "cnt = make_dataset(jtest, \"test\", cnt)\n",
    "cnt = make_dataset(jvalid, \"val\", cnt)\n",
    "#cnt = make_dataset(jvalid, \"val\", cnt)\n",
    "print(\"cnt\", cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2daa5651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./datasets/nia2022/Image/'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1b6b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
